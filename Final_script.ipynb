{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. LastFM API calls to get top love songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dependencies\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from pprint import pprint\n",
    "from config import lastfm_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Top Love Songs DataFrame to populate with info retrieved from LastFM\n",
    "top2000_lovesongs_df=pd.DataFrame({\n",
    "    \"Rank\": [],\n",
    "    \"Song Name\": [],\n",
    "    \"Artist\": [],\n",
    "    \"Duration\": [],\n",
    "    \"Album\": []\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the parameters to LastFM API calls. Method and Limit are empty so we can adjust them to specific calls\\\n",
    "#like get_top_tracks or track.getInfo\n",
    "\n",
    "params={\n",
    "    \"tag\": \"love\",\n",
    "    \"api_key\": lastfm_api,\n",
    "    \"format\": \"json\",\n",
    "    \"method\":\"\",\n",
    "    \"limit\": \"\"\n",
    "}\n",
    "\n",
    "base_url= \"http://ws.audioscrobbler.com/2.0/?\"\n",
    "example_url= \"/2.0/?method=tag.gettoptracks&tag=disco&api_key=YOUR_API_KEY&format=json\"    #taken from website\n",
    "\n",
    "\n",
    "#API call for 2000 songs using tag.getTopTracks\n",
    "params[\"limit\"]=2000\n",
    "params[\"method\"]= \"tag.gettoptracks\"\n",
    "\n",
    "response=requests.get(base_url, params=params).json()\n",
    "# pprint(response)\n",
    "\n",
    "#The 2000 songs are in a list under \"response[\"tracks\"][\"track\"]\"\n",
    "results_df=pd.DataFrame(response[\"tracks\"][\"track\"])\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The 2000 songs are in a list under \"response[\"tracks\"][\"track\"]\"\n",
    "results=response[\"tracks\"][\"track\"]\n",
    "\n",
    "for index, row in results_df.iterrows():\n",
    "    song= results[index][\"name\"]     \n",
    "    artist= results[index][\"artist\"][\"name\"]\n",
    "    print(f'Info retrieved for song:{song} by {artist}')\n",
    "    \n",
    "    #Retrieve info about date release of album and track duration\n",
    "    try:\n",
    "        song_url=f'http://ws.audioscrobbler.com/2.0/?method=track.getInfo&api_key={lastfm_api}\\\n",
    "                    &track={song}&artist={artist}&format=json'\n",
    "        song_response=requests.get(song_url).json()\n",
    "        print(f'-->Retrieving album name for {song} by {artist}')\n",
    "        album=song_response[\"track\"][\"album\"][\"title\"]\n",
    "\n",
    "    except (KeyError, IndexError, ValueError):\n",
    "        print(f'----Missing field/result for {album} by {artist}. Skipping----')\n",
    "    \n",
    "    #Populate df\n",
    "    try:\n",
    "        top2000_lovesongs_df.loc[index, \"Rank\"]=results[index][\"@attr\"][\"rank\"]\n",
    "        top2000_lovesongs_df.loc[index, \"Song Name\"]=results[index][\"name\"]\n",
    "        top2000_lovesongs_df.loc[index, \"Artist\"]=results[index][\"artist\"][\"name\"]\n",
    "        top2000_lovesongs_df.loc[index, \"Duration\"]=results[index][\"duration\"] \n",
    "        top2000_lovesongs_df.loc[index, \"Album\"]=song_response[\"track\"][\"album\"][\"title\"]\n",
    "            \n",
    "    except (KeyError, IndexError):\n",
    "        print(f'----Missing field/result for {song} by {artist}. Skipping----')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display dataframe and save as csv\n",
    "top2000_lovesongs_df.to_csv(\"csv/top2000_lovesongs_df.csv\")\n",
    "top2000_lovesongs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if all rows of the df have been populated\n",
    "#NOTE: not all songs have duration info (0). If we want to use duration to answer questions, we need to fill in the gaps\n",
    "#NOTE: some albums are missing?\n",
    "top2000_lovesongs_df.count()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAYBE  GOOD TO DO JUST FOR THE PRESENTATION, DURATION IN SECONDS IS EASIER TO MANIPULATE FOR THE ANALYSIS\n",
    "#Convert seconds in HH:MM:SS format\n",
    "def convert(seconds): \n",
    "    seconds = seconds % (24 * 3600) \n",
    "#     hour = seconds // 3600    #we don't need hours\n",
    "    seconds %= 3600\n",
    "    minutes = seconds // 60\n",
    "    seconds %= 60\n",
    "      \n",
    "#     return \"%d:%02d:%02d\" % (hour, minutes, seconds)\n",
    "    return \"%02d:%02d\" % (minutes, seconds)\n",
    "\n",
    "# Example \n",
    "n = 259\n",
    "print(convert(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Retrieve release date and lyrics from Genius\n",
    "* Find instructions here https://github.com/johnwmillr/LyricsGenius/blob/master/README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Install lyrics genius module\n",
    "# !pip install lyricsgenius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import lyricsgenius module and config with token\n",
    "import lyricsgenius\n",
    "from config import genius_token\n",
    "genius = lyricsgenius.Genius(genius_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open top_love_songs csv file\n",
    "top2000_lovesongs_df=pd.read_csv(\"csv/top2000_lovesongs_df.csv\")\n",
    "\n",
    "#add new columns to populate with year and lyrics\n",
    "top2000_lovesongs_df[\"Year\"]=\"\"\n",
    "top2000_lovesongs_df[\"Lyrics\"]=\"\"\n",
    "# top2000_lovesongs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search year and lyrics for TOP2000 songs:\n",
    "\n",
    "for index, row in top2000_lovesongs_df.iterrows():\n",
    "    title=row[\"Song Name\"]\n",
    "    artist=row[\"Artist\"]\n",
    "    print(f'Retrieving info for Index {index}: {title} by {artist}')\n",
    "    \n",
    "    try:       \n",
    "        song = genius.search_song(title, artist=artist)\n",
    "        top2000_lovesongs_df.loc[index, \"Year\"]= song.year        \n",
    "        top2000_lovesongs_df.loc[index, \"Lyrics\"]= song.lyrics\n",
    "\n",
    "        \n",
    "    except:\n",
    "        print(f'----- missing info for {title} by {artist}')\n",
    "\n",
    "print(\"FIN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store new csv to prevent re-runnning API call\n",
    "top2000_lovesongs_df.to_csv(\"top2000_yearlyrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe from new csv\n",
    "song_year_df=pd.read_csv(\"top2000_yearlyrics.csv\")\n",
    "song_year_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve year and create bins for decades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the song year on '-'\n",
    "song_year_df[['Split Year', 'xyz', 'abc']] = song_year_df.Year.str.split(\"-\",expand=True,)\n",
    "\n",
    "# drop irrelevent columns\n",
    "songs_df=song_year_df.drop([\"xyz\", \"abc\", \"Year\"], axis=1)\n",
    "\n",
    "# drop na years\n",
    "song_years_df = songs_df[songs_df['Split Year'].notna()]\n",
    "\n",
    "song_years_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop weird columns created for don't know what reason\n",
    "year_df=song_years_df.drop([\"Unnamed: 0\"], axis=1)\n",
    "\n",
    "# Rename Split Year Column\n",
    "year_df = year_df.rename(columns={\"Split Year\": \"Year\"})\n",
    "\n",
    "year_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANALYSIS: Number of top love songs per decade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast Year strings to int\n",
    "year_df['Year'] = year_df['Year'].astype(int)\n",
    "\n",
    "year_df.dtypes\n",
    "\n",
    "# bin years to see distribution\n",
    "bins = [0, 1949, 1959, 1969, 1979, 1989, 1999, 2009, 2020]\n",
    "\n",
    "# Create the names for the bins\n",
    "labels = [\"40s\", \"50s\", \"60s\", \"70s\", \"80s\", \"90s\", \"2000s\", \"2010s\"]\n",
    "\n",
    "year_df[\"bins\"] = pd.cut(year_df[\"Year\"], bins, labels=labels, include_lowest=True)\n",
    "\n",
    "# count songs per decade\n",
    "year_df[\"bins\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean data \n",
    "* drop data from 40s & 50s, remove songs from 2000s not ranked in top 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop data from 40s & 50s, remove songs from 2000s not ranked in top 300\n",
    "final_songs_df = year_df.loc[(year_df[\"bins\"] != \"40s\") & (year_df[\"bins\"] != \"50s\") & (year_df[\"bins\"] != \"2000s\")]\n",
    "\n",
    "songs_df = year_df.loc[(year_df[\"bins\"]=='2000s') & (year_df[\"Rank\"]<300)]\n",
    "\n",
    "# merge songs from 2000s back into dataframe\n",
    "final_df = pd.merge(songs_df, final_songs_df, on=[\"Song Name\", \"Artist\", \"Album\", \"Duration\", \"Rank\", \"Year\", \"bins\", \"Lyrics\"], how=\"outer\")\n",
    "final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store info in a new csv\n",
    "final_df.to_csv(\"csv/final_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count the number of unique songs for each bin (decade)\n",
    "final_df[\"bins\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Lyrics Cleanup\n",
    "* Moludes needed: Natural Language Toolkit (NLTK) \n",
    "* NLTK is a Python package for natural language processing\n",
    "* for info: https://www.nltk.org/data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Natural Language Toolkit (NLTK) is a Python package for natural language processing\n",
    "# #Install nltk module (for info: https://www.nltk.org/data.html) *takes a while to download*\n",
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Dependencies \n",
    "\n",
    "#for nlkt (remove stop words)    ---> all available datasets/models:CORPORA: http://www.nltk.org/nltk_data/\n",
    "import nltk\n",
    "nltk.download(\"stopwords\") \n",
    "\n",
    "# for punctuation, import string library function  \n",
    "import string  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open file with songs from top populated eras\n",
    "song_with_lyrics_df=pd.read_csv(\"csv/final_data.csv\")\n",
    "\n",
    "# #Drop weird column created for don't know what reason\n",
    "weird_columns=[\"Unnamed: 0\", \"Unnamed: 0.1\", \"Unnamed: 0.1.1\"]\n",
    "song_list_df=song_with_lyrics_df.drop(weird_columns, axis=1)\n",
    "\n",
    "\n",
    "song_list_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for duplicates in the list of songs\n",
    "duplicates=song_list_df.duplicated(subset=[\"Song Name\", \"Artist\"], keep=False)\n",
    "song_list_df[duplicates]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning lyrics\n",
    "* stop words (a, about, above, after, again, against, all....)\n",
    "* punctuation characters (. ; : [] ? ...)\n",
    "* words related to song structure (intro, chorus, verse)\n",
    "* numbers\n",
    "#### Create lists for:\n",
    "* word count for each song\n",
    "* unique words for each song\n",
    "* unique words count for each song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split lyrics into words, create a new df\n",
    "\n",
    "#punctuation= [',', '.', ';', ':', '[', ']', '?', '!', '(', ')', '\"', '%', \"&\", \"-\", \"--\"]  #old punctuation\n",
    "punctuation=list(string.punctuation)\n",
    "\n",
    "#(for info: https://www.geeksforgeeks.org/removing-stop-words-nltk-python/)\n",
    "stop_words= set(stopwords.words('english')) \n",
    "\n",
    "#possible verse number (as strings)\n",
    "numbers=[str(n) for n in range(10000)]\n",
    "\n",
    "#possible song structure terms and artist names\n",
    "song_structure_words=[\"intro\", \"verse\", \"chorus\", \"bridge\", \"outro\", \"hook\"]  #\"chris\", \"martin\", \n",
    "\n",
    "#list of total words, unique words (arrays) and unique_word_counts (series)\n",
    "tot_words_list=[]            #list of total number of words per song\n",
    "unique_words_list=[]         #list of unique words per song\n",
    "unique_words_count_list=[]   #list of count of unique words per song\n",
    "\n",
    "\n",
    "for index, row in song_list_df.iterrows():\n",
    "    \n",
    "    #Store song lyrics in a variable\n",
    "    song_lyrics=song_list_df[\"Lyrics\"][index]\n",
    "\n",
    "    #Before splitting lyrics into words, remove punctation characters\n",
    "    song_lyrics_clean= song_lyrics\n",
    "\n",
    "    for x in punctuation:\n",
    "        if not x == \"'\":\n",
    "            song_lyrics_clean=song_lyrics_clean.replace(x,\"\")\n",
    "\n",
    "    #Split string into list of words\n",
    "    words_list= song_lyrics_clean.split() \n",
    "\n",
    "    #Make df of lowercase words (stop words are all lowercase)\n",
    "    words_list_lower=[words_list[x].lower() for x in range(len(words_list))]\n",
    "\n",
    "    #Remove stop words such as “the”, “a”, “an”, “in” \n",
    "    filtered_1=[k for k in words_list_lower if not k in stop_words]\n",
    "\n",
    "    #remove possible verse number (as strings)\n",
    "    filtered_2=[k for k in filtered_1 if not k in numbers] \n",
    "\n",
    "    #remove song structure words     \n",
    "    filtered_lyrics_index=[k for k in filtered_2 if not k in song_structure_words] \n",
    "    \n",
    "    #Create a df for lyrics analysis\n",
    "    lyrics_index_df=pd.DataFrame()\n",
    " \n",
    "    #Save song_lyrics_clean to a new dataframe\n",
    "    lyrics_index_df[index]=filtered_lyrics_index\n",
    "    \n",
    "    #Number of words\n",
    "    tot_words=len(lyrics_index_df[index])\n",
    "    tot_words_list.append(tot_words)\n",
    "    \n",
    "    #Unique words\n",
    "    unique_words=lyrics_index_df[index].unique()\n",
    "    unique_words_list.append(unique_words)\n",
    "    \n",
    "    #Count of Unique words\n",
    "    unique_words_count=lyrics_index_df[index].value_counts()\n",
    "    unique_words_count_list.append(unique_words_count)    \n",
    "    \n",
    "    \n",
    "    #Rename column and export to csv as lyrics_index.csv\n",
    "    column_name= f'{song_list_df[\"Song Name\"][index]}_{song_list_df[\"Artist\"][index]}'\n",
    "    lyrics_index_df=lyrics_index_df.rename(columns={index: column_name})\n",
    "    lyrics_index_df.to_csv(f'Lyrics/lyrics_{index}_df.csv')\n",
    "\n",
    "lyrics_index_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of word count for each song\n",
    "tot_words_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of unique words for each song\n",
    "unique_words_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of unique words counts for each song\n",
    "unique_words_count_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANALYSIS: Word count per decade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new df with year, bin categoty and word count list\n",
    "words_count_df=pd.DataFrame({\n",
    "    \"Song Name\": song_list_df[\"Song Name\"],\n",
    "    \"Artist\": song_list_df[\"Artist\"],\n",
    "    \"Words count\": tot_words_list,\n",
    "    \"Year\": song_list_df[\"Year\"],\n",
    "    \"Bin\": song_list_df[\"bins\"]\n",
    "})\n",
    "\n",
    "words_count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot\n",
    "words_count_df.boxplot(\"Words count\", by=\"Bin\", figsize=(20,10))\n",
    "plt.title(\"Song word count per decade (era)\", fontsize=25, fontweight=\"bold\")\n",
    "plt.xlabel(\"Decade\", fontsize=20)\n",
    "plt.ylabel(\"Number of words\", fontsize=20)\n",
    "plt.savefig(\"Plots/word_count_boxplot_original.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify outliers from words_count_df with number of words >2000\n",
    "outliers=words_count_df.loc[words_count_df[\"Words count\"] > 2000]\n",
    "outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieve info for outliers in song_list_df\n",
    "outliers_df=song_list_df.loc[(song_list_df.index == 753) | (song_list_df.index == 1022)]\n",
    "outliers_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECK OUTLIERS LYRICS\n",
    "\n",
    "#A Rocket to the Moon - shhh.. Just listEn :)\n",
    "outliers_df[\"Lyrics\"][1022]\n",
    "\n",
    "#Comment: A lot info in the lyrics, like \" CAMERA EXPLORES, ATTIC - NEW ANGLE - DAY\" -----> DROP!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Beck - Everybody's Gotta Learn Sometimes\n",
    "outliers_df[\"Lyrics\"][753]\n",
    "\n",
    "#Comment: the song does exist but the lyrics belong to another song (Genius problem) (The Devil Glitch by Chris Butler\\\n",
    "#also known as the longest song ever! Full version is 1h long. https://www.youtube.com/watch?v=10SnNfxjAI8)  -----> DROP!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop outliers and plot\n",
    "words_count_clean_df=words_count_df.drop([753, 1022])\n",
    "words_count_clean_df\n",
    "\n",
    "#Plot\n",
    "words_count_clean_df.boxplot(\"Words count\", by=\"Bin\", figsize=(20,10))\n",
    "plt.title(\"Song word count per decade (Clean dataset)\", fontsize=25, fontweight=\"bold\")\n",
    "plt.xlabel(\"Decade\", fontsize=20)\n",
    "plt.ylabel(\"Number of words\", fontsize=20)\n",
    "plt.savefig(\"Plots/word_count_boxplot_clean.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check outliers: round 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify outliers from words_count_df with number of words >600\n",
    "outliers_2=words_count_clean_df.loc[words_count_clean_df[\"Words count\"] > 600] \n",
    "outliers_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieve info for outliers in song_list_df\n",
    "outliers_2_df=song_list_df.loc[(song_list_df.index == 551) | (song_list_df.index == 990)]\n",
    "outliers_2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ellie Goulding - Love Me Like You Do - From \"Fifty Shades of Grey\"\n",
    "outliers_2_df[\"Lyrics\"][551]\n",
    "\n",
    "#Comment: lyrics match from Genius is list of 2016 Grammys Nominees (https://genius.com/Grammys-2016-nominees-lyrics)\n",
    "# ----> DROP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Black Star - Brown Skin Lady\"\n",
    "outliers_2_df[\"Lyrics\"][990]\n",
    "\n",
    "#Comment: Song really has long lyrics, both members of the band (Talib Kweli and Mos Def) sing at the same time \n",
    "#(https://genius.com/Black-star-brown-skin-lady-lyrics)  ----> Could keep but it's indeed an outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop outliers\n",
    "words_count_clean_2_df=words_count_clean_df.drop([551, 990])\n",
    "words_count_clean_2_df\n",
    "\n",
    "# #Plot\n",
    "# words_count_clean_2_df.boxplot(\"Words count\", by=\"Bin\", figsize=(20,10))\n",
    "# plt.title(\"Song word count per decade (final)\", fontsize=25, fontweight=\"bold\")\n",
    "# plt.xlabel(\"Decade\", fontsize=20)\n",
    "# plt.ylabel(\"Number of words\", fontsize=20)\n",
    "# plt.savefig(\"Plots/word_count_boxplot_final_raw.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical analysis and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Statistical analysis OneWay ANOVA\n",
    "\n",
    "#create separate subsets per bin\n",
    "words_2010s=words_count_clean_2_df.loc[words_count_clean_2_df[\"Bin\"] == \"2010s\"][\"Words count\"]\n",
    "words_2000s=words_count_clean_2_df.loc[words_count_clean_2_df[\"Bin\"] == \"2000s\"][\"Words count\"]\n",
    "words_90s=words_count_clean_2_df.loc[words_count_clean_2_df[\"Bin\"] == \"90s\"][\"Words count\"]\n",
    "words_80s=words_count_clean_2_df.loc[words_count_clean_2_df[\"Bin\"] == \"80s\"][\"Words count\"]\n",
    "words_70s=words_count_clean_2_df.loc[words_count_clean_2_df[\"Bin\"] == \"70s\"][\"Words count\"]\n",
    "words_60s=words_count_clean_2_df.loc[words_count_clean_2_df[\"Bin\"] == \"60s\"][\"Words count\"]\n",
    "\n",
    "#run OneWay ANOVA\n",
    "(statistic, pvalue)=stats.f_oneway(words_2010s, words_2000s, words_90s, words_80s, words_70s, words_60s)\n",
    "pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLOT USING MATPLOTLIB, CHANGE COLORS\n",
    "fig= plt.plot(figsize=(40,20))\n",
    "labels=[\"60s\", \"70s\", \"80s\", \"90s\", \"2000s\", \"2010s\"]\n",
    "data=[words_60s, words_70s,words_80s, words_90s, words_2000s, words_2010s]\n",
    "# colors=[\"lightblue\", \"pink\", \"lightgreen\", \"purple\", \"lightorange\", \"grey\"]\n",
    "\n",
    "# rectangular box plot\n",
    "bplot = plt.boxplot(data,patch_artist=True,  # fill with color,\n",
    "                    labels=labels)  # will be used to label x-ticks\n",
    "\n",
    "plt.title(\"Song word count per decade\", fontsize=15, fontweight=\"bold\")\n",
    "plt.xlabel(\"Decade\", fontsize=12)\n",
    "plt.ylabel(\"Number of words\", fontsize=12)\n",
    "\n",
    "\n",
    "\n",
    "# fill with colors\n",
    "#Note: bplot is a dict, these are the keys: ['whiskers', 'caps', 'boxes', 'medians', 'fliers', 'means']\n",
    "colors=[\"lightblue\", \"pink\", \"lightgreen\", \"darkorchid\", \"tan\", \"silver\"]\n",
    "\n",
    "for patch, color in zip(bplot[\"boxes\"], colors):\n",
    "        patch.set_facecolor(color)\n",
    "\n",
    "#Annotate pvalue\n",
    "string_pvalue= f'pvalue=1.12e-21'\n",
    "plt.annotate(string_pvalue, (1, 400), fontsize=12, color=\"black\")\n",
    "        \n",
    "\n",
    "plt.savefig(\"Plots/word_count_boxplot_final_colors.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
